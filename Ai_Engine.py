from transformers import pipeline
import re, pandas as pd

# === 1. Model AI + dicÈ›ionar romÃ¢n ===
qa_pipeline = pipeline("text2text-generation", model="google/flan-t5-base")

context_romana = {
    "cpu": "Unitatea centralÄƒ de procesare care executÄƒ instrucÈ›iuni.",
    "alu": "Unitatea de operaÈ›ii logice È™i aritmetice.",
    "ram": "Memorie temporarÄƒ rapidÄƒ accesibilÄƒ procesorului.",
    "rom": "Memorie permanentÄƒ pentru iniÈ›ializarea sistemului.",
    "vhdl": "Limbaj hardware pentru definirea arhitecturilor logice.",
    "assembly": "Limbaj de nivel jos apropiat de structura procesorului."
}

# === 2. AnalizÄƒ Assembly ===
def analyze_assembly_code(code: str) -> str:
    lines = code.splitlines()
    suggestions = []
    for i, line in enumerate(lines):
        if re.search(r"\bmul\b.*\b2\b", line, re.IGNORECASE):
            suggestions.append(f"Linia {i+1}: ÃnlocuieÈ™te 'MUL ... 2' cu 'SHL ... 1'.")
        if re.search(r"mov\s+(\w+),\s*\1", line, re.IGNORECASE):
            suggestions.append(f"Linia {i+1}: InstrucÈ›iunea MOV e redundantÄƒ (acelaÈ™i registru).")
    return "\n".join(suggestions) if suggestions else "Codul pare curat È™i optimizat!"

# === 3. AnalizÄƒ fiÈ™iere JSON ===
def analyze_json_metrics(file_path: str) -> str:
    df = pd.read_json(file_path)
    summary = f"""
ğŸ“Š AnalizÄƒ JSON:
- Coloane: {', '.join(df.columns)}
- Medii: {df.mean(numeric_only=True).to_dict()}
- CorelaÈ›ii:
{df.corr(numeric_only=True).round(2).to_string()}
"""
    return summary

# === 4. FuncÈ›ie unicÄƒ de chat AI ===
def chat_response(message: str, code: str = "", data_path: str = "") -> str:
    message = message.lower()

    # DacÄƒ vrea analizÄƒ de cod JSON
    if "json" in message or "metrice" in message:
        if data_path:
            return analyze_json_metrics(data_path)
        return "Te rog sÄƒ Ã®ncarci un fiÈ™ier JSON pentru analizÄƒ."

    # DacÄƒ e cod assembly
    if "assembly" in message or "optimizeazÄƒ" in message or "cod" in message:
        explanation = analyze_assembly_code(code)
        prompt = f"ExplicÄƒ acest cod È™i sugestiile pentru utilizator: {explanation}. Ãntrebarea: {message}"
    else:
        # DicÈ›ionar fallback
        for key in context_romana:
            if key in message:
                prompt = f"ExplicÄƒ ce Ã®nseamnÄƒ '{key}' pe Ã®nÈ›elesul tuturor: {context_romana[key]}. Ãntrebarea completÄƒ: {message}"
                break
        else:
            prompt = f"FormuleazÄƒ un rÄƒspuns clar È™i empatic Ã®n limba romÃ¢nÄƒ pentru: '{message}'"

    result = qa_pipeline(prompt, max_new_tokens=120)[0]["generated_text"]
    return result
